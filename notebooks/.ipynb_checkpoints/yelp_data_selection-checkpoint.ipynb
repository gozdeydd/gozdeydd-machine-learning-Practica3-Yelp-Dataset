{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ramiz11/Yelp-EDA/blob/main/yelp_data_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxhOV8D6sLEJ"
   },
   "source": [
    "# *yelp* dataset - data selection for EDA\n",
    "This part has been run locally, in order to deal with Github's upload size limitation, which is 25MB per file.\n",
    "Here we load the Yelp datasets, create and save a subset = all restaurants in a selected city, and save it for Github upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R84vbr_lnMzq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "import pickle                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zM7a3xTtw3LZ"
   },
   "source": [
    "### Read & save the pre-downloaded Yelp Json files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zblBMcUoxCow"
   },
   "outputs": [],
   "source": [
    "def load_rows(filepath, skip=0, nrows = None):\n",
    "    with open(filepath, encoding='utf8') as json_file:\n",
    "        read_count, load_count = 0, 0\n",
    "        objs = []\n",
    "        line = json_file.readline()\n",
    "        while (nrows is None or load_count < nrows) and line:\n",
    "            read_count += 1\n",
    "            if read_count > skip:\n",
    "                obj = json.loads(line)\n",
    "                objs.append(obj)\n",
    "                load_count += 1\n",
    "                if load_count % 10000 == 0:\n",
    "                    print(load_count, 'loaded')\n",
    "            line = json_file.readline()\n",
    "    return pd.DataFrame(objs)\n",
    "\n",
    "dirname = 'c:/data/yelp/'\n",
    "EDA_dir = 'c:/data/yelp/eda/'\n",
    "\n",
    "business = pd.read_json(Path(dirname, 'yelp_academic_dataset_business.json'), lines=True)\n",
    "business.to_pickle(Path(dirname, 'business.pkl'))\n",
    "\n",
    "checkin = pd.read_json(Path(dirname, 'yelp_academic_dataset_checkin.json'), lines=True)\n",
    "checkin.to_pickle(Path(dirname, 'checkin.pkl'))\n",
    "\n",
    "# read reviews in 2 parts due to its size\n",
    "rev1 = load_rows(Path(dirname, 'yelp_academic_dataset_review.json'), 0, 4000000)\n",
    "rev2 = load_rows(Path(dirname, 'yelp_academic_dataset_review.json'), 4000000)\n",
    "review = pd.concat([rev1, rev2])\n",
    "review.to_pickle(Path(dirname, 'review.pkl'))\n",
    "\n",
    "tip = pd.read_json(Path(dirname, 'yelp_academic_dataset_tip.json'), lines=True)\n",
    "tip.to_pickle(Path(dirname, 'tip.pkl'))\n",
    "\n",
    "user = pd.read_json(Path(dirname, 'yelp_academic_dataset_user.json'), lines=True)\n",
    "user.to_pickle(Path(dirname, 'user.pkl')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QgXvt1YxO-N"
   },
   "source": [
    "### Subset the data for our EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgTuBGYdzWrc"
   },
   "source": [
    "##### Focus on restaurants: \n",
    "how many restaurants are there out of all businesses?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8Pb-o6SxV2P"
   },
   "outputs": [],
   "source": [
    "is_rest = business['categories'].str.contains('Restaurant', na=False)\n",
    "is_rest.value_counts(normalize=True, ascending=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAce4M6rzrJ9"
   },
   "source": [
    "##### So it's about a third. Let's subset and check the expected files size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3DDgNUWzyRP"
   },
   "outputs": [],
   "source": [
    "business = business[business.categories.str.contains('Restaurant', na=False)]\n",
    "df_bytes = business.memory_usage(deep=True).sum()\n",
    "print('business rows:', f'{len(business):,}', 'bytes in memory:', f'{df_bytes:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWVsPnHF0usC"
   },
   "source": [
    "##### Subset further - look for a medium sized city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDrZkiMc0v-R"
   },
   "outputs": [],
   "source": [
    "business.city.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZh0GxI80_5H"
   },
   "source": [
    "##### Select Cleveland, subset all dataframes according to its bussinesses and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85GLek7j1B_1"
   },
   "outputs": [],
   "source": [
    "business = business[business.city == 'Cleveland']\n",
    "checkin = checkin[checkin.business_id.isin(business.business_id)]\n",
    "tip = tip[tip.business_id.isin(business.business_id)]\n",
    "review = review[review.business_id.isin(business.business_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewmwP6zi9Fn_"
   },
   "source": [
    "#### Reviews is pontentially another big file, check its size..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SnJGgb29FBO"
   },
   "outputs": [],
   "source": [
    "df_bytes = business.memory_usage(deep=True).sum()\n",
    "print('review rows:', f'{len(review):,}', 'bytes in memory:', f'{df_bytes:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhLw0gNK1kts"
   },
   "source": [
    "##### Reduce reviews size by keeping them for the two most recent years: 2018, 2019\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUgP860Q1lpR"
   },
   "outputs": [],
   "source": [
    "review = review[pd.to_datetime(review.date).dt.to_period('Y').astype(str).astype(int).isin([2018, 2019])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNxdK1IW9afO"
   },
   "source": [
    "##### Continue with users data, and check its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Li6gEKJj9sJl"
   },
   "outputs": [],
   "source": [
    "user = user[user.user_id.isin(review.user_id)]\n",
    "df_bytes = user.memory_usage(deep=True).sum()\n",
    "print('user rows:', f'{len(user):,}', 'bytes in memory:', f'{df_bytes:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9h-cDY4A9kb9"
   },
   "source": [
    "##### Looks good! save in pickle files to be uploaded to Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe10cTV--DTe"
   },
   "outputs": [],
   "source": [
    "business.to_pickle(Path(EDA_dir, 'business.pkl'))\n",
    "checkin.to_pickle(Path(EDA_dir, 'checkin.pkl'))\n",
    "review.to_pickle(Path(EDA_dir, 'review.pkl'))\n",
    "tip.to_pickle(Path(EDA_dir, 'tip.pkl'))\n",
    "user.to_pickle(Path(EDA_dir, 'user.pkl'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "yelp data selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
